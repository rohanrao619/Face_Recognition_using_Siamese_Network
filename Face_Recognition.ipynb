{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Face_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RZLbKvhna2Q"
      },
      "source": [
        "# Force TensorFlow v1 (on Google Colab)\r\n",
        "\r\n",
        "%tensorflow_version 1.x\r\n",
        "\r\n",
        "import tensorflow\r\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjneMzGxDhGd"
      },
      "source": [
        "# Install MTCNN library for face detection\n",
        "\n",
        "!pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po6pXsPbTTyu"
      },
      "source": [
        "# Import required packages\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras.models import load_model,model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EFsZHawnnZ5"
      },
      "source": [
        "# Load pretrained Inception-ResNet-v1 model\n",
        "# Update model and weights path according to your working environment\n",
        "\n",
        "model_path = \"Models/Inception_ResNet_v1.json\"\n",
        "weights_path = \"Models/facenet_keras_weights.h5\"\n",
        "\n",
        "json_file = open(model_path, 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "enc_model = model_from_json(loaded_model_json)\n",
        "enc_model.load_weights(weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LINQ1ZzCbEYw"
      },
      "source": [
        "# Initialize a MTCNN face detector\n",
        "\n",
        "mtcnn_detector = MTCNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "060X7dGbUaJJ"
      },
      "source": [
        "# Function to detect and extract face from a image\n",
        "\n",
        "def detect_face(filename, required_size=(160, 160),normalize = True):\n",
        "\n",
        "    img = Image.open(filename)\n",
        "\n",
        "    # convert to RGB\n",
        "    img = img.convert('RGB')\n",
        " \n",
        "    # convert to array\n",
        "    pixels = np.asarray(img)\n",
        " \n",
        "    # detect faces in the image\n",
        "    results = mtcnn_detector.detect_faces(pixels)\n",
        " \n",
        "    # extract the bounding box from the first face\n",
        "    x1, y1, width, height = results[0]['box']\n",
        "\n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "\n",
        "    # extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "  \n",
        "    # resize pixels to the model size\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = asarray(image)\n",
        " \n",
        "    if normalize == True:\n",
        "\n",
        "        mean = np.mean(face_array, axis=(0,1,2), keepdims=True)\n",
        "        std = np.std(face_array, axis=(0,1,2), keepdims=True)\n",
        "        std_adj = np.maximum(std, 1.0)\n",
        "        return (face_array - mean) / std\n",
        "\n",
        "    else : \n",
        "        return face_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMzpMGNe4HgU"
      },
      "source": [
        "# Compute Face encodings and load IDs of known persons\n",
        "# Update face database path according to your working environment\n",
        "\n",
        "known_faces_encodings = []\n",
        "known_faces_ids = []\n",
        "\n",
        "known_faces_path = \"Face_database/\"\n",
        "\n",
        "for filename in os.listdir(known_faces_path):\n",
        "  \n",
        "  # Detect faces\n",
        "  face = detect_face(known_faces_path+filename,normalize = True)\n",
        "\n",
        "  # Compute face encodings\n",
        "\n",
        "  feature_vector = enc_model.predict(face.reshape(1,160,160,3))\n",
        "  feature_vector/= np.sqrt(np.sum(feature_vector**2))\n",
        "  known_faces_encodings.append(feature_vector)\n",
        "\n",
        "  # Save Person IDs\n",
        "  label = filename.split('.')[0]\n",
        "  known_faces_ids.append(label)\n",
        "\n",
        "\n",
        "known_faces_encodings = np.array(known_faces_encodings).reshape(len(known_faces_encodings),128)\n",
        "known_faces_ids = np.array(known_faces_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S60cggIBBR2"
      },
      "source": [
        "# No. of known IDs loaded from database\n",
        "\n",
        "print(known_faces_ids.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyV6Eyd3XkA8"
      },
      "source": [
        "# Function to recognize a face (if it is in known_faces)\n",
        "\n",
        "def recognize(img,known_faces_encodings,known_faces_ids,threshold = 0.75):\n",
        "\n",
        "  scores = np.zeros((len(known_faces_ids),1),dtype=float)\n",
        "\n",
        "  enc = enc_model.predict(img.reshape(1,160,160,3))\n",
        "  enc/= np.sqrt(np.sum(enc**2))\n",
        "\n",
        "  scores = np.sqrt(np.sum((enc-known_faces_encodings)**2,axis=1))\n",
        "\n",
        "  match = np.argmin(scores)\n",
        "\n",
        "  if scores[match] > threshold :\n",
        "\n",
        "    return (\"UNKNOWN\",0)\n",
        "      \n",
        "  else :\n",
        "\n",
        "    return (known_faces_ids[match],scores[match])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1okFKhLStsHD"
      },
      "source": [
        "# Function to perform real-time face recognition through a webcam\n",
        "\n",
        "def face_recognition(mode,file_path,known_faces_encodings,known_faces_ids,\n",
        "                         detector = 'haar', threshold = 0.75):\n",
        "\n",
        "  if detector == 'haar':\n",
        "\n",
        "    # Load the cascade\n",
        "    face_cascade = cv2.CascadeClassifier('Models/haarcascade_frontalface_default.xml')\n",
        "\n",
        "  if mode == 'webcam':\n",
        "\n",
        "    # To capture webcam feed. Change argument for differnt webcams\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "  elif mode == 'video':\n",
        "    # To capture video feed \n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    \n",
        "  while True:\n",
        "\n",
        "    # Read the frame\n",
        "    _, img = cap.read()\n",
        "    \n",
        "    # Stop if end of video file\n",
        "    if _ == False:\n",
        "        break;\n",
        "\n",
        "    if detector == 'haar':\n",
        "    \n",
        "      #Convert to grayscale\n",
        "      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      # Detect the faces\n",
        "      faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    elif detector == 'mtcnn' :  \n",
        "\n",
        "      results = mtcnn_detector.detect_faces(img)\n",
        "      \n",
        "      if(len(results)==0):\n",
        "        continue\n",
        "\n",
        "      faces = []\n",
        "    \n",
        "      for i in range(len(results)):\n",
        "        \n",
        "        x,y,w,h = results[i]['box']\n",
        "        x, y = abs(x), abs(y)\n",
        "        faces.append([x,y,w,h])\n",
        "\n",
        "    # Draw the rectangle around each face\n",
        "    for (x, y, w, h) in faces:\n",
        "        \n",
        "        image = Image.fromarray(img[y:y+h, x:x+w])\n",
        "        image = image.resize((160,160))\n",
        "        face_array = asarray(image)\n",
        "\n",
        "        # Normalize\n",
        "        mean = np.mean(face_array, axis=(0,1,2), keepdims=True)\n",
        "        std = np.std(face_array, axis=(0,1,2), keepdims=True)\n",
        "        std_adj = np.maximum(std, 1.0)\n",
        "        face_array_normalized = (face_array - mean) / std\n",
        "\n",
        "        # Recognize\n",
        "        label = recognize(face_array_normalized,known_faces_encodings,known_faces_ids,threshold = 0.75)\n",
        "        \n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\n",
        "        cv2.putText(img, label[0], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)\n",
        "\n",
        "    # Display\n",
        "    cv2.imshow('Face_Recognition', img)\n",
        "    \n",
        "    # Stop if escape key is pressed\n",
        "    key = cv2.waitKey(25) & 0xff\n",
        "    if key==27:\n",
        "        break\n",
        "\n",
        "  # Release the VideoCapture object\n",
        "  cap.release() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoVzEG5Qz4zF"
      },
      "source": [
        "# Execute Face recognition on a webcam feed.\n",
        "# Note : Threshold has to be adjusted according to your requirements !\n",
        "\n",
        "face_recognition('webcam',None,known_faces_encodings,known_faces_ids,\n",
        "                 detector = 'haar',threshold = 0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeRZlEJXVJZh"
      },
      "source": [
        "# Execute Face recognition on a Video file.\n",
        "# Note : Threshold has to be adjusted according to your requirements !\n",
        "\n",
        "face_recognition('video',\"test.mp4\",known_faces_encodings,known_faces_ids,\n",
        "                 detector = 'mtcnn',threshold = 0.75)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}